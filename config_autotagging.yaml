model:
    name: AutoTagging
    block_l:
    - sequential_l:
        - layer_l:
# Temporal
            #- [LayerNorm, {'normalized_shape': [1, 3200]}]
# SincNet            
            #- [SincNet, {'in_channels': 1, 'out_channels': 80, 'kernel_size': 251, 'stride': 1, 'sr_hz': 16000}]
            #- [AbsLayer, empty]
# Conv1D
            #- [Conv1d, {'in_channels': 1, 'out_channels': 80, 'kernel_size': 251, 'stride': 15}]
# TCN
            #- [Conv1dTCN, {'in_channels': 1, 'num_channels': [4, 8, 16, 32]}]
# Frequency/Time
            - [LayerNorm, {'normalized_shape': [128, 64]}]
            - [Conv2d, {'in_channels': 1, 'out_channels': 80, 'kernel_size': [128, 5], 'stride': [1,1]}]
            - [Squeeze, {'dim': 2}]
# All temporal
            #- [MaxPool1d, {'kernel_size': 3, 'stride': 3}]
# All            
            - [LayerNorm, {'normalized_shape': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - [Conv1d, {'in_channels': -1, 'out_channels': 60, 'kernel_size': 5, 'stride': 1}]
            - [MaxPool1d, {'kernel_size': 3, 'stride': 3}] 
            - [LayerNorm, {'normalized_shape': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - [Conv1d, {'in_channels': -1, 'out_channels': 60, 'kernel_size': 5, 'stride': 1}]
            - [MaxPool1d, {'kernel_size': 3, 'stride': 3}]
            - [LayerNorm, {'normalized_shape': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - ['Permute', {'shape': [0, 2, 1]}]
    - sequential_l:
        - layer_l:
            - [LayerNorm, {'normalized_shape': -1}]
            - [Linear, {'in_features': -1, 'out_features': 128}] # --- 2048 -> 128
            - [BatchNorm1dT, {'num_features': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - [Linear, {'in_features': -1, 'out_features': 128}] # --- 2048 -> 128
            - [BatchNorm1dT, {'num_features': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - [Linear, {'in_features': -1, 'out_features': 128}] # --- 2048 -> 128
            - [BatchNorm1dT, {'num_features': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - ['Permute', {'shape':[0, 2, 1]}]
        - layer_l:
            - [Mean, {'dim': 2}]
    - sequential_l:
        - layer_l:
            - [Linear, {'in_features': -1, 'out_features': 10}]
    #          - [Activation, Softmax]
